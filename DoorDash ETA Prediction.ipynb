{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4701c030-873a-407e-9bed-ddecb0545feb",
   "metadata": {},
   "source": [
    "# DoorDash ETA Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca40833f-53de-45cc-aeba-6820d60c03c2",
   "metadata": {},
   "source": [
    "## Overview\n",
    "The dataset used for this project is sourced from DoorDash deliveries in early 2015, capturing the details of various orders in a subset of cities. The primary goal of this analysis is to predict the estimated time taken for delivery, measured in total seconds from when an order is placed (`created_at`) to when it is delivered (`actual_delivery_time`). This prediction is crucial for improving customer experience on the DoorDash platform.\n",
    "\n",
    "## Data Description\n",
    "The dataset is provided in a CSV file called `historical_data.csv` and includes several columns representing different aspects of each delivery.\n",
    "\n",
    "### Columns in the Dataset:\n",
    "1. **Time Features:**\n",
    "   - `market_id`: Identifier for the city/region (e.g., Los Angeles).\n",
    "   - `created_at`: Timestamp in UTC when the order was submitted.\n",
    "   - `actual_delivery_time`: Timestamp in UTC when the order was delivered.\n",
    "\n",
    "2. **Store Features:**\n",
    "   - `store_id`: Identifier for the restaurant where the order was placed.\n",
    "   - `store_primary_category`: Cuisine category of the restaurant (e.g., Italian, Asian).\n",
    "   - `order_protocol`: An identifier denoting the order mode used by the store.\n",
    "\n",
    "3. **Order Features:**\n",
    "   - `total_items`: Total number of items in the order.\n",
    "   - `subtotal`: Total value of the order (in cents).\n",
    "   - `num_distinct_items`: Number of unique items in the order.\n",
    "   - `min_item_price`: Price of the cheapest item (in cents).\n",
    "   - `max_item_price`: Price of the most expensive item (in cents).\n",
    "\n",
    "4. **Market Features:**\n",
    "   - `total_onshift_dashers`: Number of available delivery drivers within 10 miles of the store at the time of order.\n",
    "   - `total_busy_dashers`: Number of those drivers who are currently occupied with an order.\n",
    "   - `total_outstanding_orders`: Number of orders being processed within 10 miles of the current order.\n",
    "\n",
    "5. **Predictions from Other Models:**\n",
    "   - `estimated_order_place_duration`: Estimated time for the restaurant to receive the order (in seconds).\n",
    "   - `estimated_store_to_consumer_driving_duration`: Estimated travel time between the store and the consumer (in seconds).\n",
    "\n",
    "## Data Characteristics\n",
    "- **Unit of Time**: All time values are recorded in seconds.\n",
    "- **Monetary Values**: Dollar amounts are expressed in cents.\n",
    "- **Time Zones**: The timestamps are given in UTC, with the relevant timezone being US/Pacific.\n",
    "\n",
    "## Objective\n",
    "The aim of this analysis is to develop a model that accurately predicts the delivery duration, helping DoorDash enhance service quality and meet consumer expectations more effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e9c798-197f-4c22-b207-90620ca0a5de",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b929f1d-3a71-4d52-acc5-abb167463a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import holidays\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import KNNImputer\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8b5ad08-b884-4236-80f2-6c565cafffbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv(r'C:\\Users\\mprat\\Downloads\\historical_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f42e228-ca76-4cee-ae0d-bb0bd15a09b6",
   "metadata": {},
   "source": [
    "### Convert and Extract Datetime Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df6df71-16e3-43cc-ab92-9ffa06d10b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datetime columns\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data['actual_delivery_time'] = pd.to_datetime(data['actual_delivery_time'])\n",
    "data['delivery_duration_minutes'] = (\n",
    "    (data['actual_delivery_time'] - data['created_at']).dt.total_seconds() / 60\n",
    ")\n",
    "\n",
    "# Time-Based Features\n",
    "data['hour'] = data['created_at'].dt.hour\n",
    "data['day_of_week_num'] = data['created_at'].dt.dayofweek\n",
    "data['is_weekend'] = data['day_of_week_num'].isin([5, 6]).astype(int)\n",
    "\n",
    "# Holiday Indicator\n",
    "us_holidays = holidays.US()\n",
    "data['is_holiday'] = data['created_at'].dt.date.astype(str).isin(us_holidays).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d909e18-3ee2-459e-aa18-46179cc5e97c",
   "metadata": {},
   "source": [
    "### Datetime Conversion\n",
    "- **`created_at` and `actual_delivery_time`**: Converts string datetime columns into `datetime` type, enabling easy extraction of date-related features.\n",
    "\n",
    "### Target Variable\n",
    "- **`delivery_duration_minutes`**: Calculates the target variable, representing the delivery time in minutes. This is essential for model training to predict delivery times.\n",
    "\n",
    "### Time-Based Features\n",
    "- **`hour`**: Helps the model learn hourly patterns in delivery times.\n",
    "- **`day_of_week_num`**: Allows the model to capture trends based on the day of the week.\n",
    "- **`is_weekend`**: Indicates whether the delivery was on a weekend, helping the model understand delivery time variations during weekends.\n",
    "\n",
    "### Holiday Indicator\n",
    "- **`is_holiday`**: Marks whether the delivery occurred on a holiday, which can impact delivery times due to reduced availability or increased demand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb94a91-ba04-421d-906c-f24d26f230d2",
   "metadata": {},
   "source": [
    "## Dasher Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43489851-eeea-4d49-99e9-54bfb993e813",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['total_busy_dashers'] = abs(data['total_busy_dashers'])  # Handle negative values\n",
    "data['total_onshift_dashers'] = abs(data['total_onshift_dashers'])\n",
    "data['dashers_per_order'] = data['total_onshift_dashers'] / (data['total_outstanding_orders'] + 1e-5)\n",
    "data['%_dashers_avail'] = data['total_busy_dashers'] / (\n",
    "    data['total_busy_dashers'] + data['total_onshift_dashers'] + 1e-5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288d6743-b5c7-4c9c-a6cd-05332f8d4c90",
   "metadata": {},
   "source": [
    "- **`total_busy_dashers`**: Ensures non-negative values for better modeling and reflects available resources.\n",
    "- **`total_onshift_dashers`**: Ensures non-negative values, representing the total number of dashers working.\n",
    "- **`dashers_per_order`**: Calculates the ratio of dashers to outstanding orders, helping the model understand how resource availability affects delivery time.\n",
    "- **`%_dashers_avail`**: Represents the proportion of busy dashers compared to the total, providing insight into overall availability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d354cb-1096-4467-a33a-1602a3f1a689",
   "metadata": {},
   "source": [
    "## Price-Based Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cc71d1-223e-4575-9dd7-729e3d564da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['price_range'] = data['max_item_price'] - data['min_item_price']\n",
    "data['avg_item_price'] = data['subtotal'] / (data['total_items'] + 1e-5)\n",
    "data['price_volatility'] = data['price_range'] / (data['avg_item_price'] + 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97a7f49-a4d8-49a9-9096-0cdc6b27c2d7",
   "metadata": {},
   "source": [
    "- **`price_range`**: Measures the difference between the highest and lowest item prices, giving insight into price volatility.\n",
    "- **`avg_item_price`**: Calculates the average item price per order, contributing to understanding how item pricing may affect delivery.\n",
    "- **`price_volatility`**: Shows the variability in price within an order, indicating potential impacts on order handling and delivery times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d46b8b-57d2-48ae-abd0-6be8fb323ae9",
   "metadata": {},
   "source": [
    "## Interaction Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0c3578-3d18-49c2-8597-5dd9fa996c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interaction Features\n",
    "data['order_intensity'] = data['total_outstanding_orders'] / (data['total_busy_dashers'] + 1e-5)\n",
    "data['delivery_difficulty'] = data['order_intensity'] * data['delivery_duration_minutes']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a393b6-4a8d-4f22-8730-fca57d38b590",
   "metadata": {},
   "source": [
    "- **`order_intensity`**: Represents the ratio of total outstanding orders to busy dashers, providing an indication of workload and potential delivery time impacts.\n",
    "- **`delivery_difficulty`**: The interaction of order intensity and delivery duration, capturing how workload complexity impacts delivery times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99414db5-c453-4b55-b9fe-0d141437ad2f",
   "metadata": {},
   "source": [
    "## Delivery Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a52ecb-3615-4b8e-8a1a-f11fa1d0bc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['delivery_speed'] = data['delivery_duration_minutes'] / (\n",
    "    data['estimated_store_to_consumer_driving_duration'] / 60 + 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c9a564-bb66-4ca1-8119-285752de022d",
   "metadata": {},
   "source": [
    "- **`delivery_speed`**: Measures the ratio of delivery duration to estimated store-to-consumer driving duration, indicating how efficiently deliveries are made."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3fd039-8699-4038-bd6c-8693cea4e2f3",
   "metadata": {},
   "source": [
    "## Log Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706d6d42-ec9c-404c-9e96-48dbdd5d5a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['log_subtotal'] = np.log1p(data['subtotal'])\n",
    "data['log_outstanding_orders'] = np.log1p(data['total_outstanding_orders'].clip(lower=1e-5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bf3d3d-7517-42b0-926a-42c746a3d2f9",
   "metadata": {},
   "source": [
    "- **`log_subtotal`**: Applies a log transformation to the subtotal for better handling of skewed data and reducing the impact of outliers.\n",
    "- **`log_outstanding_orders`**: Applies a log transformation to the number of outstanding orders, ensuring a better scale and reducing data skew.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "11e716fa-8589-447a-b524-8e415ef2b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['created_at', 'actual_delivery_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55658eb7-5c0b-4983-8ea5-4484ed10a040",
   "metadata": {},
   "source": [
    "# Outlier Removal Using IQR Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c8b05ed-8c4a-40ee-8a10-b4e50fd720ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_iqr(df, variables, threshold=1.5):\n",
    "   \n",
    "    for variable in variables:\n",
    "        if variable in df.columns:\n",
    "            Q1 = df[variable].quantile(0.25)\n",
    "            Q3 = df[variable].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - (threshold * IQR)\n",
    "            upper_bound = Q3 + (threshold * IQR)\n",
    "            df = df[(df[variable] >= lower_bound) & (df[variable] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "# Define numerical columns with potential outliers\n",
    "outlier_columns = [\n",
    "    'subtotal', 'delivery_duration_minutes', 'max_item_price', 'price_range',\n",
    "    'avg_item_price', 'price_volatility', 'delivery_speed'\n",
    "]\n",
    "\n",
    "# Remove outliers\n",
    "data = remove_outliers_iqr(data, outlier_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e358add4-9e52-46d3-91f6-7e000c1be197",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Columns Processed\n",
    "The following numerical columns are targeted for outlier removal:\n",
    "- `subtotal`: The total value of items in an order.\n",
    "- `delivery_duration_minutes`: The total delivery time in minutes.\n",
    "- `max_item_price`: The highest item price in an order.\n",
    "- `price_range`: The difference between the maximum and minimum item prices.\n",
    "- `avg_item_price`: The average price of items in an order.\n",
    "- `price_volatility`: The variability of item prices.\n",
    "- `delivery_speed`: The ratio of delivery duration to estimated driving duration.\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfed2819-b20e-416e-9a19-c0f8eab11a4b",
   "metadata": {},
   "source": [
    "# Handling Missing Values in the Dataset\n",
    "### Using KNN Imputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7daa4de-61a9-4853-910c-9e4844851a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column after imputation:\n",
      "market_id                                       0\n",
      "store_id                                        0\n",
      "store_primary_category                          0\n",
      "order_protocol                                  0\n",
      "total_items                                     0\n",
      "subtotal                                        0\n",
      "num_distinct_items                              0\n",
      "min_item_price                                  0\n",
      "max_item_price                                  0\n",
      "total_onshift_dashers                           0\n",
      "total_busy_dashers                              0\n",
      "total_outstanding_orders                        0\n",
      "estimated_order_place_duration                  0\n",
      "estimated_store_to_consumer_driving_duration    0\n",
      "delivery_duration_minutes                       0\n",
      "hour                                            0\n",
      "day_of_week_num                                 0\n",
      "is_weekend                                      0\n",
      "is_holiday                                      0\n",
      "dashers_per_order                               0\n",
      "%_dashers_avail                                 0\n",
      "price_range                                     0\n",
      "avg_item_price                                  0\n",
      "price_volatility                                0\n",
      "order_intensity                                 0\n",
      "delivery_difficulty                             0\n",
      "delivery_speed                                  0\n",
      "log_subtotal                                    0\n",
      "log_outstanding_orders                          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def handle_missing_values(df, n_neighbors=5):\n",
    "    \n",
    "    # Handle numerical columns using KNN Imputer\n",
    "    numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "    df[numeric_cols] = imputer.fit_transform(df[numeric_cols])\n",
    "    \n",
    "    # Handle categorical columns using mode imputation\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "    for col in categorical_cols:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply missing value handling\n",
    "data = handle_missing_values(data)\n",
    "print(\"Missing values per column after imputation:\")\n",
    "print(data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2245ebde-1a7f-4519-b5d0-4bf3ac83f28e",
   "metadata": {},
   "source": [
    "### 1. Numerical Columns:\n",
    "- **KNN Imputer**: Uses the k-nearest neighbors algorithm to estimate missing values based on the similarity to other rows. The number of neighbors (`n_neighbors`) can be adjusted to control the influence of nearby data points.\n",
    "\n",
    "### 2. Categorical Columns:\n",
    "- **Mode Imputation**: Fills missing values with the most frequent value (mode) of the column. This ensures that categorical columns retain the most common category, maintaining the overall distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab307629-3553-499f-9d51-15d073e447e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This Method requires less computation power but not much reliable in outier data(we consider this when we require the outliers fix in less time)\n",
    "\n",
    "'''def handle_missing_values(df):\n",
    "    # Handle numerical columns using median imputation for efficiency\n",
    "    numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    for col in numeric_cols:\n",
    "        df[col].fillna(df[col].median(), inplace=True)\n",
    "    \n",
    "    # Handle categorical columns using mode imputation\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "    for col in categorical_cols:\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "    \n",
    "    return df'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18090d82-296e-4ae2-87c7-dab52e386f75",
   "metadata": {},
   "source": [
    "# Optimized Label Encoding for Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84be6f9c-9936-4642-9ce8-cdd287f30fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimized_label_encoding(df, cat_cols):\n",
    "    le_dict = {} \n",
    "    \n",
    "    for col in cat_cols:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col].astype(str))\n",
    "        le_dict[col] = le \n",
    "    \n",
    "    return df, le_dict\n",
    "    \n",
    "categorical_columns = ['store_primary_category']\n",
    "data, encoders = optimized_label_encoding(data, categorical_columns)\n",
    "\n",
    "data['store_primary_category'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc0d72f-103b-4afa-b788-b659205e4ee4",
   "metadata": {},
   "source": [
    "Label encoding is used to convert categorical values into numeric values so that machine learning algorithms can process them efficiently.\n",
    "It is not fit for nominal values but instead of using OneHot Encoder which cause enormous amount of columns or like Target encoder may cause to a data leak, it is better in this way.\n",
    "\n",
    "- The function iterates over the specified columns (`cat_cols`), fits the encoder on each column, and transforms the column values accordingly.\n",
    "- The encoder for each column is stored in a dictionary (`le_dict`) for potential future use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fa6930-8058-44c6-a458-e5b96ba331e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target and feature variables\n",
    "X = data.drop(columns=['delivery_duration_minutes'])\n",
    "y = data['delivery_duration_minutes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f117cde3-db71-4efa-ab14-a6a5863b1821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc2de8a-e2e1-425c-a930-cc2dd81d4846",
   "metadata": {},
   "source": [
    "# Linear Regression Model for Predicting Delivery Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "def91fda-2735-497e-aae5-668f8998bb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 4.82\n",
      "Root Mean Squared Error (RMSE): 6.55\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#Evaluate the model using MAE and RMSE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473ba2a2-b0b5-4280-9cef-fa07139bdea6",
   "metadata": {},
   "source": [
    "# LightGBM Model for Predicting Delivery Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "baf6b994-03a5-4cba-9fa9-f672d490e93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023128 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4801\n",
      "[LightGBM] [Info] Number of data points in the train set: 126109, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 44.448571\n",
      "Mean Absolute Error (MAE): 0.58\n",
      "Root Mean Squared Error (RMSE): 1.00\n"
     ]
    }
   ],
   "source": [
    "lgb_model = lgb.LGBMRegressor(\n",
    "    objective='regression',\n",
    "    metric='rmse',\n",
    "    num_leaves=31,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=200,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "lgb_model.fit(X_train, y_train)\n",
    "y_pred = lgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using MAE and RMSE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837d2f34-9f1e-4205-924d-c70aa5d06af6",
   "metadata": {},
   "source": [
    "# Neural Network Model for Predicting Delivery Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5e691ef8-7c2d-4006-a727-181b6451db39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mprat\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3153/3153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 230.9714 - mae: 9.7173 - val_loss: 11.6799 - val_mae: 2.5707\n",
      "Epoch 2/50\n",
      "\u001b[1m3153/3153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 30.7224 - mae: 3.9855 - val_loss: 6.6142 - val_mae: 1.8162\n",
      "Epoch 3/50\n",
      "\u001b[1m3153/3153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 23.0373 - mae: 3.3683 - val_loss: 5.2353 - val_mae: 1.6206\n",
      "Epoch 4/50\n",
      "\u001b[1m3153/3153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 18.9243 - mae: 2.9653 - val_loss: 2.7135 - val_mae: 1.1528\n",
      "Epoch 5/50\n",
      "\u001b[1m3153/3153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 11.4643 - mae: 2.3472 - val_loss: 5.5476 - val_mae: 1.8334\n",
      "Epoch 6/50\n",
      "\u001b[1m3153/3153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 7.3584 - mae: 1.9115 - val_loss: 3.8692 - val_mae: 1.4157\n",
      "Epoch 7/50\n",
      "\u001b[1m3153/3153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 5.5738 - mae: 1.6581 - val_loss: 5.6098 - val_mae: 1.7425\n",
      "Epoch 8/50\n",
      "\u001b[1m3153/3153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 4.6946 - mae: 1.5149 - val_loss: 3.7093 - val_mae: 1.4694\n",
      "Epoch 9/50\n",
      "\u001b[1m3153/3153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 4.1934 - mae: 1.4337 - val_loss: 5.0795 - val_mae: 1.7367\n",
      "Epoch 10/50\n",
      "\u001b[1m3153/3153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 3.7033 - mae: 1.3534 - val_loss: 6.4058 - val_mae: 1.8975\n",
      "Epoch 11/50\n",
      "\u001b[1m3153/3153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 3.3812 - mae: 1.2981 - val_loss: 4.0993 - val_mae: 1.5599\n",
      "Epoch 12/50\n",
      "\u001b[1m3153/3153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 3.2254 - mae: 1.2542 - val_loss: 5.5207 - val_mae: 1.7099\n",
      "Epoch 13/50\n",
      "\u001b[1m3153/3153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 3.2077 - mae: 1.2477 - val_loss: 5.5413 - val_mae: 1.7482\n",
      "Epoch 14/50\n",
      "\u001b[1m3153/3153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 3.0565 - mae: 1.2238 - val_loss: 5.0615 - val_mae: 1.7620\n",
      "\u001b[1m986/986\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "MAE: 1.16\n",
      "RMSE: 1.67\n"
     ]
    }
   ],
   "source": [
    "neural_model = Sequential([\n",
    "    Dense(128, input_dim=X_train.shape[1], activation='relu'),\n",
    "    Dropout(0.2),  \n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2), \n",
    "    Dense(32, activation='relu'),  \n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "neural_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',  \n",
    "    patience=10,  \n",
    "    restore_best_weights=True  \n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = neural_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,  \n",
    "    epochs=50,  \n",
    "    batch_size=32, \n",
    "    callbacks=[early_stopping]  \n",
    ")\n",
    "\n",
    "# Step 7: Model Evaluation\n",
    "y_pred = neural_model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da917797-9adc-42f1-b2c9-cf2ebb65418d",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "## Summary of Analysis\n",
    "The DoorDash ETA prediction dataset offers valuable insights into factors influencing delivery times, capturing essential details from order placement to final delivery. Key variables impacting delivery durations include time-based features, store and market conditions, and order characteristics. Notably, the number of available dashers and their status, the number of items in the order, and store type are significant contributors to delivery time.\n",
    "\n",
    "## Key Findings\n",
    "- **Temporal Patterns**: Delivery times are influenced by the time of order creation and market congestion. Higher numbers of outstanding orders and active dashers correlate with longer delivery times.\n",
    "- **Order Complexity**: Larger orders with more items and higher total subtotals generally lead to longer delivery times.\n",
    "- **Store Influence**: The type of store and dasher availability in its vicinity affect delivery speed, suggesting that optimizing dasher distribution relative to store location and order volume can improve efficiency.\n",
    "- **Model Performance**: Predictive features such as `estimated_order_place_duration` and `estimated_store_to_consumer_driving_duration` can be used effectively for accurate ETA predictions.\n",
    "\n",
    "## Model Performance Summary\n",
    "\n",
    "| **Model**          | **Mean Absolute Error (MAE) in minutes** | **Root Mean Squared Error (RMSE)in minutes** |\n",
    "|--------------------|-------------------------------|------------------------------------|\n",
    "| **LightGBM**       | 0.58                          | 1.00                               |\n",
    "| **Neural Network** | 1.16                          | 1.67                               |\n",
    "| **Linear Regression** | 4.82                       | 6.55                               |\n",
    "\n",
    "## Analysis and Recommendations\n",
    "\n",
    "### 1. LightGBM Model\n",
    "- **Best Performance**: LightGBM showed the highest accuracy with an MAE of **0.58** and an RMSE of **1.00**, demonstrating its capability to handle complex relationships in the data effectively.\n",
    "- **Implications**: LightGBM is the ideal model for ETA predictions due to its accuracy and efficiency with large datasets. Further optimization through hyperparameter tuning and feature engineering can improve results even more.\n",
    "\n",
    "### 2. Neural Network Model\n",
    "- **Moderate Performance**: The neural network had an MAE of **1.16** and RMSE of **1.67**, which is better than linear regression but not as effective as LightGBM.\n",
    "- **Implications**: While neural networks can model complex data, their performance here suggests that they need more tuning and training adjustments to match or exceed LightGBM.\n",
    "\n",
    "### 3. Linear Regression Model\n",
    "- **Weakest Performance**: The linear regression model had the highest errors with an MAE of **4.82** and RMSE of **6.55**, indicating it cannot capture the data's complexities adequately.\n",
    "- **Implications**: Linear regression may be used for initial benchmarks or when interpretability is prioritized over predictive accuracy.\n",
    "\n",
    "## Recommendations for Improving Delivery Times\n",
    "\n",
    "### Key Factors Affecting Delivery Time\n",
    "- **Time-Based Features**: Delivery times are significantly affected by the time of order placement and time of day.\n",
    "- **Geographical and Traffic Conditions**: Locations and traffic influence delivery speed.\n",
    "- **Order Size and Complexity**: Larger or more complex orders take longer to handle.\n",
    "- **External Conditions**: Weather and unforeseen events can also impact delivery times.\n",
    "\n",
    "### Suggested Improvements for Business Optimization and Enhanced Model Performance\n",
    "\n",
    "1. **Integrate Real-Time Data**: Utilize APIs for live traffic, weather, and event updates to dynamically adjust ETAs.\n",
    "2. **Peak Time Analysis**: Identify and manage peak hours by adjusting scheduling to minimize delays.\n",
    "3. **Advanced Routing**: Implement route optimization algorithms considering real-time conditions.\n",
    "4. **Data Enrichment**: Include more detailed location and external factors like traffic congestion.\n",
    "5. **Feature Engineering**: Develop new features representing traffic congestion patterns and seasonal variations.\n",
    "6. **Automated Adjustments**: Train models on historical data with traffic and weather as features to adapt to real-time conditions.\n",
    "7. **Feedback Loops**: Regularly compare actual delivery times with predictions to refine the model.\n",
    "\n",
    "### Data Enhancements\n",
    "- **Expand Feature Set**: Add variables such as driver experience and order priority.\n",
    "- **Ensure Data Quality**: Validate data accuracy for consistency in time, distance, and delivery details.\n",
    "- **Reduce Noise**: Apply data cleaning techniques to minimize anomalies and ensure a realistic dataset.\n",
    "\n",
    "### Future Model Enhancements\n",
    "- **Hyperparameter Tuning**: Optimize LightGBM parameters using grid search or Bayesian methods.\n",
    "- **Ensemble Methods**: Combine strengths of LightGBM, neural networks, and linear regression for a robust solution.\n",
    "- **Continuous Updates**: Regularly refresh training data to adapt to changes in delivery patterns, traffic, and weather.\n",
    "\n",
    "## Final Thoughts\n",
    "Understanding the factors impacting delivery times enables DoorDash to take proactive measures that enhance delivery efficiency and customer experience. Implementing the strategies discussed can lead to more accurate ETAs and optimized resource allocation, ultimately improving service quality on the platform.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6410c34-6bf8-4752-ad0b-d721867dfec4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
